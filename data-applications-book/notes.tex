\documentclass[14pt]{extarticle}

\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{helvet}
\usepackage{microtype}
\usepackage{hyperref}

\renewcommand{\familydefault}{\sfdefault}

\title{Designing Data-Intensive Applications\\Notes}
\author{}
\date{}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section*{How to Use This Template}
\addcontentsline{toc}{section}{How to Use This Template}
\begin{itemize}
  \item Create a new \textbf{Chapter} section for each audiobook chapter.
  \item Capture key ideas, notable quotes, and takeaways in the provided subsections.
  \item Add action items or open questions you want to revisit.
\end{itemize}
\newpage

\section{Chapter \# -- Title}
\subsection{General}
\begin{itemize}
  \item Redis, Apache Kafka (boundaries blurred)
  \item Single tool can't any longer meet data needs 
  \item work is broken down into tasks into multiple tools
  \item mem-cached, elastic search, solar -- application code keeps all this synced
  \item API hides implementation details from clients
  \item how do you ensure data remains correct and complete? 
  \item how do you scale? 
  \item what API is best? 
  \item how do you have an issue but the client can still be fine
  \item Book considers 3 concerns: reliability (toyota style), scalability, maintainibility (chnaging people should be able to work on the system productively)
  \item following chapters: architectures and algos important to achieve these
  \item Reliability: 
  \item faults and fault tolerant systems in reliability
  \item fault is one component of a system deviating from its spec
  \item failure: system as a whole stops providing the service to the user
  \item fault tolerance mechanisms are important 
  \item Netflix Chaos Monkey: a revolutionary tool that randomly disables virtual machines and services in its production environment to test system resilience
  \item hard disk MTTF (mean time to failure) is 10-50 years, 10000 disks, on average 1 disk to die per day
  \item mo machines mo problems
  \item Virutal Machine instances stop running without warning because it is sometimes needed somewhere else 
  \item Software Errors: 
  \item independent events generally, a large number don't fail all at once 
  \item automated testing: config changes -> possible issues -> slow rollout so only a few users are affected if at all 
  \item telemetry: track and monitor failures
  \item discussing scalablility is trying to figure out how to cope with growth in whichever way you are growing (current load, and then incr. load)
  \item twitter example (Nov 2012 data): 4600 req./s, views 300,000 req/s, tweet volume + fan out. Two ways of implementing follower followee. Global collection is an option and then you merge those where follower and followee (original approach). do more work at write time and less at read time so just write the tweets on their home timelines (new approach). "Fan out load". Twitter now hybrids b/w the 2. Celebs are fetched separately like in Approach 1. 
  \item System performance based on load parameters
  \item performance numbers: Hadoop -- care about "Throughput"
  \item median is good, mean is whatever
  \item how bad are outliers? check percentiles like 95th, 99th, 99.5th
  \item response time requirements at amazon are defined using p999 (99.9th percentile). (slowest one in 1000 requests) They focus on the most valuable customers. The website should be lightning fast for that top 0.1\% of person
  \item 99.99th percentile is too hard and too expensive so you do the next best possible thing
  \item Percentiles in practice: End user request needs to still wait for the slowest of the parallel processes. So a small percentage of slow processed requests can slow down the process a lot so you need to focus on trying to make the slowest ones faster kinda always. good, better, best. never let it rest. till your good gets better. and your better gets best. bears on 3. 1 2 3 BEARS
  \item Tail Latency Amplification is what that previous item is called 
  \item Forward Decay, T-Digest, HDR Histogram (algo examples that can calculate a good approx. of percentiles at min cpu and memory cost, the other way would be too expensive -- trying to calculate all request times in a minute and sorting them by time) 
  \item Right way of aggregating response time data is histograms 
  \item approaches for coping with load:
  \item shared nothing architecture -- high end machines get expensive so you can't scale out sometimes so you have one machine
  \item no such thing as a one size fits all scaling architecure: volume of reads/writes, the volume of data to store, data complexity, response time requirements, access patters, usually a combination of them all
  \item a system designed to handle a 100k 1kB requests in a minute is different that one designed to handle 3 2gB requests in a minute.
  \item load parameters <8 early stage startups need to be able to iterate on product things more than they need to focus on having a "perfectly scalable" architecture 
  \item don't create legacy software
  \item 3 design principles: operability, simplicity (not UI but engineers should be able to figure ts out), adaptability (no easy solutions but you create systems that try to achieve this)
  \item ops teams >>>>
  \item 
\end{itemize}

\subsection*{Key Ideas}
\begin{itemize}
  \item
  \item
  \item
\end{itemize}

\subsection*{Architecture / Systems Mentioned}
\begin{itemize}
  \item
\end{itemize}

\subsection*{Concepts and Definitions}
\begin{itemize}
  \item \textbf{Term}: Definition or explanation.
\end{itemize}

\subsection*{Diagrams / Mental Models}
\begin{itemize}
  \item
\end{itemize}

\subsection*{Notable Quotes}
\begin{itemize}
  \item ``''
\end{itemize}

\subsection*{Questions / Confusions}
\begin{itemize}
  \item
\end{itemize}

\subsection*{Practical Takeaways}
\begin{itemize}
  \item
\end{itemize}

\subsection*{Action Items}
\begin{itemize}
  \item
\end{itemize}

\newpage

% Duplicate the chapter template below as needed.

\end{document}
